{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"NR_Dataset.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"}},"cells":[{"cell_type":"code","metadata":{"id":"C83XgaWprQnn","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","!pip install torch-geometric \\\n","  torch-sparse==latest+cu101 \\\n","  torch-scatter==latest+cu101 \\\n","  torch-cluster==latest+cu101 \\\n","  -f https://pytorch-geometric.com/whl/torch-1.5.0.html"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gRUdaEpW2GsF","colab_type":"text"},"source":["!pip install torch-geometric \\\n","  torch-sparse==latest+cu101 \\\n","  torch-scatter==latest+cu101 \\\n","  torch-cluster==latest+cu101 \\\n","  -f https://pytorch-geometric.com/whl/torch-1.5.0.html"]},{"cell_type":"code","metadata":{"id":"anKz91FjrQn3","colab_type":"code","outputId":"15e78714-bcee-4877-832e-f703b83d1e5d","executionInfo":{"status":"ok","timestamp":1588929257688,"user_tz":-330,"elapsed":1493,"user":{"displayName":"Ammar Ameerdeen","photoUrl":"","userId":"11235069741153318262"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","from functools import reduce\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.data import Data, DataLoader, InMemoryDataset\n","\n","import numpy as np\n","import pandas as pd\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('running on '+ (\"GPU\" if torch.cuda.is_available() else \"CPU\"))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["running on CPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFsXKb1CzwSY","colab_type":"code","outputId":"cf679564-4f82-4606-f13f-77ef4b9c139e","executionInfo":{"status":"ok","timestamp":1588929260119,"user_tz":-330,"elapsed":1366,"user":{"displayName":"Ammar Ameerdeen","photoUrl":"","userId":"11235069741153318262"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","PATH = '/content/drive/My Drive/rubber'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lX8YjbZkzjeA","colab_type":"code","colab":{}},"source":["class Seq2SeqDataSet(InMemoryDataset):\n","    def __init__(self, root, input_sequence, output_sequence, transform=None, pre_transform=None):\n","        super(Seq2SeqDataSet, self).__init__(root, transform, pre_transform)\n","        self.data, self.slices = torch.load(self.processed_paths[0])\n","\n","    @property\n","    def raw_dir(self):\n","      if os.path.exists(self.root+PROCESSED_DIR):\n","        return self.root+'/cleaned'\n","      else:\n","        os.mkdir(self.root+PROCESSED_DIR)\n","        return self.root+'/cleaned'\n","        \n","    @property\n","    def processed_dir(self):\n","      if os.path.exists(self.root+PROCESSED_DIR):\n","        return self.root+PROCESSED_DIR\n","      else:\n","        os.mkdir(self.root+PROCESSED_DIR)\n","        return self.root+PROCESSED_DIR\n","\n","    @property\n","    def raw_file_names(self):\n","      mypath = self.raw_dir\n","      filenames = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n","      return filenames\n","\n","    @property\n","    def processed_file_names(self):\n","        return ['processed.dt']\n","\n","    def download(self):\n","        pass\n","    \n","    def process(self):\n","      output_size , output_sequence_len, input_sequence_len= configuration['output_size'],\\\n","      configuration['output_sequence_len'],\\\n","      configuration['input_sequence_len'],\n","        \n","      data_list = []\n","\n","      for raw_path in self.raw_paths:\n","        df = pd.read_csv(raw_path)\n","        for synthetic_seq in df['synthesis_seq'].unique():\n","          synthetic_data = df[df['synthesis_seq']==synthetic_seq]\n","\n","          for country in synthetic_data['countryterritoryCode'].unique():\n","            country_data = synthetic_data[synthetic_data['countryterritoryCode'] == country]\n","                        \n","            del country_data['synthesis_seq']\n","            del country_data['countryterritoryCode']\n","\n","            country_data_i = country_data[:-output_sequence_len]\n","            country_data_array = country_data_i.to_numpy()\n","            feature_length = len(country_data.columns)\n","            x = country_data_array#[:feature_length].T\n","\n","            country_data_o = country_data[input_sequence_len:]\n","            #country_data_array = country_data_array.reshape(feature_length,len(country_data_i))\n","            country_data_array_y = np.array([country_data_o['NATURAL_RUBBER_EXPORT'].to_numpy()])\n","            country_data_array_y = country_data_array_y.reshape(output_size,len(country_data_o))\n","            y = country_data_array_y[:output_size].T\n","\n","            #print(country_data_array.shape)\n","            #print(country_data_array[0])\n","            \n","            \n","            #print(x.shape)\n","            sets =0\n","            x_list = []\n","            dict_x = dict()\n","            for i in range(input_sequence_len):\n","              array_len = (len(x)-i) - ((len(x)  - i)%input_sequence_len)+i\n","              if array_len <= 0:\n","                print('skipping')\n","                continue\n","              sets = int( array_len/ input_sequence_len)\n","              if sets <= 0:\n","                print('skipping')\n","                continue\n","              #print(len(x))\n","              #print('input seq : ', i , ' ', array_len , ' ',array_len-i , ' number of sets : ', sets)\n","              x_temp = x[i:array_len].T.reshape(sets, feature_length, input_sequence_len)\n","              uniq_keys = np.array([i+k*input_sequence_len for k in range(sets)])\n","              x_temp = x_temp.reshape(feature_length,sets,input_sequence_len)\n","              arrays_split = np.hsplit(x_temp,sets)\n","              dict_x.update(dict(zip(uniq_keys, arrays_split)))\n","\n","            dict_y = dict()\n","            y_list = []\n","            for i in range(output_sequence_len):\n","              array_len_y = (len(y)-i) - ((len(y)  - i)%output_sequence_len)+i\n","              if array_len_y <= 0:\n","                continue\n","              sets = int(array_len_y / output_sequence_len)\n","              if sets <= 0:\n","                continue\n","              y_temp = y[i:array_len_y].T.reshape(sets, output_size, output_sequence_len)\n","              #uniq_keys = np.array([i+(output_sequence_len*k) for k in range(output_sequence_len)])\n","              uniq_keys = np.array([i+k*output_sequence_len for k in range(sets)])\n","              y_temp = y_temp.reshape(output_size,sets,output_sequence_len)\n","              arrays_split = np.hsplit(y_temp,sets)\n","              dict_y.update(dict(zip(uniq_keys, arrays_split)))\n","\n","            temp_x_list = []\n","            mean = np.mean(country_data.to_numpy(), axis=0).T\n","            std = np.std(country_data.to_numpy(), axis=0).T\n","            #print(sorted(dict_x.keys()))\n","            for i in sorted(dict_x.keys()):\n","              x = dict_x[i].squeeze()\n","              #print(x.T[0][12])\n","              x = (x.T - mean) / std\n","              where_are_NaNs = isnan(x)\n","              x[where_are_NaNs] = 0\n","              temp_x_list.append(x)\n","\n","            temp_y_list  = [dict_y[i].T for i in sorted(dict_y.keys())]\n","\n","            #_country_code,popData2018\n","            xy_list = [Data(x = torch.from_numpy(features).type(torch.FloatTensor).squeeze()) for features in temp_x_list]\n","            \n","            mean_y = np.mean(y)\n","            std_y = np.std(y)\n","            for i in sorted(dict_y.keys()):\n","              temp_y_list[i] = temp_y_list[i].squeeze()\n","              norm_y = (temp_y_list[i] -mean_y)/std_y\n","              xy_list[i].y = torch.from_numpy(norm_y).squeeze()\n","\n","            data_list += xy_list\n","        print('processed : '+ raw_path)\n","      data, slices = self.collate(data_list)\n","      torch.save((data, slices), self.processed_paths[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lVuEPSrx4RTy","colab_type":"code","colab":{}},"source":["#save this with the dataset notebook\n","configuration = {\n","    'input_sequence_len' : 6,\n","    'output_sequence_len' : 6,\n","    'training_batch_size' : 2048,\n","    'training_dataset_length' :32768,\n","    'validation_batch_size' : 1024,\n","    'yhat_size' : 1,\n","    'feature_len' : 21,\n","    'output_size' : 1,\n","}\n","\n","INPUT_ROOT = PATH+'/input_mix'\n","CLEAN_DIR = 'cleaned_non_window'\n","DATA_TAG = \"non_window_seq2seq_\"+str(configuration['input_sequence_len'])+'_'+str(configuration['output_sequence_len'])\n","PROCESSED_DIR = '/processed_'+DATA_TAG\n","\n","if os.path.exists(INPUT_ROOT+'/validation'+PROCESSED_DIR):\n","  for mypath in os.listdir(INPUT_ROOT+'/validation'+PROCESSED_DIR):\n","    os.remove(INPUT_ROOT+'/validation'+PROCESSED_DIR+'/'+mypath)\n","\n","validation_dataset = CovidDataSet(INPUT_ROOT+'/training', configuration['input_sequence_len'], configuration['input_sequence_len'])\n","\n","export = []\n","for i in range(len(validation_dataset)):\n","  export.append(validation_dataset[i].x.detach().numpy()[0][12])\n","\n","\n","validation_cleaned = pd.read_csv(INPUT_ROOT+'/validation/cleaned/DATA-25_seq.csv')\n","original_variable = np.array(validation_cleaned['OIL_PRICE'].tolist())\n","#print(export)\n","#print(original_variable)\n","original_variable = (original_variable - np.mean(original_variable, axis=0))/np.std(original_variable, axis=0)\n","\n","orange_patch = mpatches.Patch(color='orange', label='Original')\n","blue_patch = mpatches.Patch(color='blue', label='After Processed')\n","plt.figure(figsize=(10,5))\n","plt.plot(original_variable)\n","plt.plot(export)\n","\n","plt.legend(handles=[ blue_patch, orange_patch])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yy5lUMGF4SGV","colab_type":"code","colab":{}},"source":["export = [0 for i in range(configuration['output_sequence_len'])]\n","\n","for i in range(len(validation_dataset)):\n","  export.append(validation_dataset[i].y.detach().numpy()[0])\n","\n","validation_cleaned = pd.read_csv(INPUT_ROOT+'/validation/cleaned/DATA-25_seq.csv')\n","original_export = np.array(validation_cleaned['NATURAL_RUBBER_EXPORT'].tolist())\n","original_export = (original_export - np.mean(original_export))/np.std(original_export)\n","plt.figure(figsize=(10,5))\n","plt.plot(original_export)\n","plt.plot(export)\n","\n","orange_patch = mpatches.Patch(color='orange', label='Original')\n","blue_patch = mpatches.Patch(color='blue', label='After Processed')\n","\n","plt.legend(handles=[ blue_patch, orange_patch])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fT0LUWio2hJp","colab_type":"code","outputId":"2c461191-ec06-47ab-d132-3a9c4bfcbc07","executionInfo":{"status":"ok","timestamp":1588929528094,"user_tz":-330,"elapsed":1652,"user":{"displayName":"Ammar Ameerdeen","photoUrl":"","userId":"11235069741153318262"}},"colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["#os.remove(INPUT_ROOT+\"/processed/pre_transform.pt\")\n","#os.remove(INPUT_ROOT+\"/processed/processed.dt\")\n","#os.remove(INPUT_ROOT+\"/processed/pre_filter.pt\")\n","#test dataset and loader\n","input_sequence_len = 6\n","output_sequence_len = 6\n","output_size = 1\n","feature_length = 23\n","INPUT_ROOT = PATH+'/input_mix/validation'\n","DATA_TAG = \"seq2seq_5_5\"\n","PROCESSED_DIR = '/processed_'+DATA_TAG\n","\n","test_dataset = CovidDataSet(INPUT_ROOT, input_sequence_len, input_sequence_len)\n","print(test_dataset[0].x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1.9452e+08, 2.6121e+01, 8.3100e+01, 1.6300e+00, 1.0000e+00, 1.0230e+04,\n","         2.6300e+00, 4.9500e+02, 0.0000e+00, 8.7020e+03, 3.7600e+02, 2.9700e+02,\n","         2.5000e+01, 9.6705e+03, 2.5240e+02, 1.8350e+02, 0.0000e+00, 1.2925e+04,\n","         1.3850e+02, 2.3800e+02, 2.1692e+02, 6.1190e+01, 1.4240e+02],\n","        [2.6550e+02, 2.6110e+02, 5.3970e+01, 3.2775e+02, 1.3154e+08, 2.6550e+01,\n","         1.0746e+02, 5.5000e-01, 1.0000e+00, 8.5610e+03, 5.2500e+00, 2.7100e+02,\n","         0.0000e+00, 9.7495e+03, 2.2500e+02, 1.8350e+02, 2.5000e+01, 1.2685e+04,\n","         1.3900e+02, 2.8500e+02, 7.0000e+00, 1.3352e+04, 1.5400e+02],\n","        [2.6025e+02, 0.0000e+00, 9.3925e+03, 2.9700e+02, 2.8850e+02, 1.9379e+02,\n","         8.1720e+01, 3.0800e+02, 1.9978e+08, 2.6415e+01, 9.8140e+01, 4.1000e-01,\n","         1.0000e+00, 9.6705e+03, 7.9400e+00, 1.6850e+02, 0.0000e+00, 1.2945e+04,\n","         1.2350e+02, 2.9280e+02, 2.1000e+01, 1.3465e+04, 1.6200e+02],\n","        [2.6725e+02, 2.5000e+01, 9.3755e+03, 3.2975e+02, 2.7300e+02, 0.0000e+00,\n","         9.4550e+03, 3.0050e+02, 3.2350e+02, 3.0185e+02, 1.0628e+02, 3.6650e+02,\n","         2.0212e+08, 2.6707e+01, 9.0980e+01, 6.9000e-01, 1.0000e+00, 1.2585e+04,\n","         7.1900e+00, 2.3400e+02, 0.0000e+00, 1.3490e+04, 1.4000e+02],\n","        [2.5700e+02, 0.0000e+00, 9.4535e+03, 2.9700e+02, 2.8850e+02, 2.4000e+01,\n","         9.6700e+03, 3.0800e+02, 3.8000e+02, 0.0000e+00, 8.8525e+03, 3.7600e+02,\n","         2.5150e+02, 2.7098e+02, 1.0005e+02, 1.9000e+02, 2.3316e+08, 2.6090e+01,\n","         8.0610e+01, 6.7000e-01, 1.0000e+00, 1.3265e+04, 8.4500e+00],\n","        [1.4000e+01, 1.0000e+00, 9.2325e+03, 9.2300e+00, 2.6850e+02, 0.0000e+00,\n","         9.6700e+03, 2.7150e+02, 3.8000e+02, 2.5000e+01, 8.8025e+03, 3.7750e+02,\n","         2.5000e+02, 0.0000e+00, 1.1580e+04, 1.8500e+02, 1.3040e+02, 2.6682e+02,\n","         4.4130e+01, 1.1200e+02, 2.3143e+08, 2.6945e+01, 8.2170e+01],\n","        [2.0400e+02, 2.1213e+08, 2.6046e+01, 8.3840e+01, 9.4000e-01, 1.0000e+00,\n","         9.3100e+03, 2.6200e+00, 3.0650e+02, 0.0000e+00, 8.9725e+03, 3.5750e+02,\n","         2.6100e+02, 2.4000e+01, 1.0930e+04, 2.0250e+02, 1.3480e+02, 0.0000e+00,\n","         1.4050e+04, 1.0970e+02, 1.8500e+02, 1.8550e+02, 7.1980e+01],\n","        [1.8450e+02, 3.1600e+02, 3.0538e+02, 5.8150e+01, 1.3650e+02, 1.6621e+08,\n","         2.6688e+01, 1.3456e+02, 6.3000e-01, 1.0000e+00, 8.7875e+03, 3.2900e+00,\n","         2.4700e+02, 0.0000e+00, 1.1670e+04, 1.8100e+02, 1.3600e+02, 2.3000e+01,\n","         1.3495e+04, 1.1210e+02, 1.7500e+02, 0.0000e+00, 1.3325e+04],\n","        [2.0425e+02, 3.2800e+02, 0.0000e+00, 9.2200e+03, 1.2800e+02, 3.5350e+02,\n","         2.8171e+02, 1.1624e+02, 4.3210e+02, 2.2726e+08, 2.6397e+01, 9.5190e+01,\n","         9.1000e-01, 1.0000e+00, 1.0920e+04, 5.5900e+00, 1.2610e+02, 0.0000e+00,\n","         1.4140e+04, 1.0390e+02, 1.8900e+02, 2.5000e+01, 1.3301e+04],\n","        [1.7675e+02, 3.3000e+02, 2.2000e+01, 9.3100e+03, 1.3670e+02, 3.7500e+02,\n","         0.0000e+00, 9.1750e+03, 3.9000e+02, 3.5500e+02, 2.7624e+02, 1.0252e+02,\n","         2.8110e+02, 2.2427e+08, 2.6124e+01, 8.5020e+01, 1.7200e+00, 1.0000e+00,\n","         1.3474e+04, 7.5700e+00, 1.7200e+02, 0.0000e+00, 1.3411e+04],\n","        [4.2100e+01, 3.1300e+02, 0.0000e+00, 9.3600e+03, 9.9000e+01, 3.7500e+02,\n","         2.4000e+01, 9.0300e+03, 4.4500e+02, 3.9200e+02, 0.0000e+00, 9.1905e+03,\n","         2.9200e+02, 2.1650e+02, 1.9039e+02, 5.4790e+01, 1.4800e+02, 2.1716e+08,\n","         2.6092e+01, 8.3610e+01, 4.0000e-01, 1.0000e+00, 1.3296e+04],\n","        [8.3120e+01, 2.3240e+01, 1.0000e+00, 9.1950e+03, 5.3000e+00, 3.3500e+02,\n","         0.0000e+00, 9.3850e+03, 3.9000e+02, 3.9450e+02, 2.6000e+01, 9.1525e+03,\n","         3.1250e+02, 2.3300e+02, 0.0000e+00, 1.1360e+04, 1.6300e+02, 1.5050e+02,\n","         1.1423e+02, 5.3590e+01, 1.2710e+02, 2.3704e+08, 2.7081e+01]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nb_DeAve1ndZ","colab_type":"code","outputId":"411a98c9-238d-4bbd-d884-39885f3dfe33","executionInfo":{"status":"error","timestamp":1588929571222,"user_tz":-330,"elapsed":2854,"user":{"displayName":"Ammar Ameerdeen","photoUrl":"","userId":"11235069741153318262"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["n= len(test_dataset)\n","print('possible batch sizes : ', set(reduce(list.__add__, ([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0))))\n","batch_size = 1\n","\n","def data_set_is_correct():\n","  test_dataloader = DataLoader(test_dataset, batch_size)\n","  for batch in test_dataloader:\n","    inputs = np.array([\n","                       batch.x.view(batch_size, input_sequence_len, feature_length)[26+i][-1][0].item() for i in range(feature_length)\n","              ])\n","    output = batch.y.view(batch_size, output_sequence_len, output_size)[25+i][0:feature_length].T[0].detach().numpy()\n","    return np.sum(output-inputs) == 0\n","\n","if data_set_is_correct() == True: print('Dataset is correct')\n","else: print('Corrupt dataset')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["possible batch sizes :  {1, 11, 121}\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-76c5e297f130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mdata_set_is_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset is correct'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Corrupt dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-53-76c5e297f130>\u001b[0m in \u001b[0;36mdata_set_is_correct\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     inputs = np.array([\n\u001b[0;32m----> 9\u001b[0;31m                        \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m               ])\n\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-53-76c5e297f130>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     inputs = np.array([\n\u001b[0;32m----> 9\u001b[0;31m                        \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m               ])\n\u001b[1;32m     11\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 26 is out of bounds for dimension 0 with size 1"]}]},{"cell_type":"code","metadata":{"id":"tPbzihD2kcDx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}